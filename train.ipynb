{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d788f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
    "import torch\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit\", # Llama 3.2 vision support\n",
    "    \"unsloth/Llama-3.2-11B-Vision-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit\", # Can fit in a 80GB card!\n",
    "    \"unsloth/Llama-3.2-90B-Vision-bnb-4bit\",\n",
    "\n",
    "    \"unsloth/Pixtral-12B-2409-bnb-4bit\",              # Pixtral fits in 16GB!\n",
    "    \"unsloth/Pixtral-12B-Base-2409-bnb-4bit\",         # Pixtral base model\n",
    "\n",
    "    \"unsloth/Qwen2-VL-2B-Instruct-bnb-4bit\",          # Qwen2 VL support\n",
    "    \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Qwen2-VL-72B-Instruct-bnb-4bit\",\n",
    "\n",
    "    \"unsloth/llava-v1.6-mistral-7b-hf-bnb-4bit\",      # Any Llava variant works!\n",
    "    \"unsloth/llava-1.5-7b-hf-bnb-4bit\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\",\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a71e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # False if not finetuning vision layers\n",
    "    finetune_language_layers   = True, # False if not finetuning language layers\n",
    "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
    "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
    "    r = 16,           # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha = 16,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0.3,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    "    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47765ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "input_file = \"qwen_dataset/train.json\"\n",
    "with open(input_file, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"watermark_new/wikiart_01817.png\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a70f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import json\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# Define schema\n",
    "class Validate(BaseModel):\n",
    "    watermarks: int\n",
    "    text: str\n",
    "    main_object: str\n",
    "    style: str\n",
    "\n",
    "# Schema as JSON Schema\n",
    "schema_as_str = json.dumps(Validate.model_json_schema())\n",
    "\n",
    "# Instruction with strict JSON requirement\n",
    "instruction = \"\"\"\n",
    "You are an image analysis system. Analyze the provided image and return only a valid JSON object that exactly follows this schema:\n",
    "{\n",
    "  \"watermarks\": integer,\n",
    "  \"text\": string,\n",
    "  \"main_object\": string,\n",
    "  \"style\": string\n",
    "}\n",
    "Rules:\n",
    "Output must be strictly valid JSON, with no explanations or extra text.\n",
    "\"watermarks\" = integer (use 0 if none).\n",
    "\"text\" = any detected text in the image (empty string if none).\n",
    "\"main_object\" = the primary subject of the image in plain English.\n",
    "\"style\" = choose exactly one from the following list:\n",
    "\"Abstract_Expressionism\"\n",
    "\"Action_painting\"\n",
    "\"Analytical_Cubism\"\n",
    "\"Art_Nouveau\"\n",
    "\"Baroque\"\n",
    "\"Color_Field_Painting\"\n",
    "\"Contemporary_Realism\"\n",
    "\"Cubism\"\n",
    "\"Early_Renaissance\"\n",
    "\"Expressionism\"\n",
    "\"Fauvism\"\n",
    "\"High_Renaissance\"\n",
    "\"Impressionism\"\n",
    "\"Mannerism_Late_Renaissance\"\n",
    "\"Minimalism\"\n",
    "\"Naive_Art_Primitivism\"\n",
    "\"New_Realism\"\n",
    "\"Northern_Renaissance\"\n",
    "\"Pointillism\"\n",
    "\"Pop_Art\"\n",
    "\"Post_Impressionism\"\n",
    "\"Realism\"\n",
    "\"Rococo\"\n",
    "\"Romanticism\"\n",
    "\"Symbolism\"\n",
    "\"Synthetic_Cubism\"\n",
    "\"Ukiyo_e\"\n",
    "\"\"\" \n",
    "# Compose chat input\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},  # <-- your image placeholder token\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Stream output while enforcing schema\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=128,\n",
    "    use_cache=True,\n",
    "    temperature=0.7,  # lower temp = more reliable structured JSON\n",
    "    min_p=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "FastVisionModel.for_training(model) # Enable for training!\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = UnslothVisionDataCollator(model, tokenizer), # Must use!\n",
    "    train_dataset = converted_dataset,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 100,\n",
    "        # num_train_epochs = 1, # Set this instead of max_steps for full training runs\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",     # For Weights and Biases\n",
    "        # You MUST put the below items for vision finetuning:\n",
    "        remove_unused_columns = False,\n",
    "        dataset_text_field = \"\",\n",
    "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
    "        max_length = 2048,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"lora_model\")  # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"watermark_new/wikiart_01244.png\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from unsloth import FastVisionModel\n",
    "    model, tokenizer = FastVisionModel.from_pretrained(\n",
    "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        load_in_4bit = True, # Set to False for 16bit LoRA\n",
    "    )\n",
    "    FastVisionModel.for_inference(model) # Enable for inference!\n",
    "\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# Define schema\n",
    "class Validate(BaseModel):\n",
    "    watermarks: int\n",
    "    text: str\n",
    "    main_object: str\n",
    "    style: str\n",
    "\n",
    "# Schema as JSON Schema\n",
    "schema_as_str = json.dumps(Validate.model_json_schema())\n",
    "\n",
    "# Instruction with strict JSON requirement\n",
    "instruction = \"\"\"\n",
    "You are an image analysis system. Analyze the provided image and return only a valid JSON object that exactly follows **this schema including the exact key names**:\n",
    "{\n",
    "  \"watermarks\": integer,\n",
    "  \"text\": string,\n",
    "  \"main_object\": string,\n",
    "  \"style\": string\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Output must be strictly valid JSON (no comments, no explanations, no text outside braces).\n",
    "- \"watermarks\" = integer (use 0 if none).\n",
    "- \"text\" = any detected text in the image (empty string if none).\n",
    "- \"main_object\" = the primary subject of the image in plain English.\n",
    "- \"style\" = choose exactly one from the following list:\n",
    "[\"Abstract_Expressionism\",\"Action_painting\",\"Analytical_Cubism\",\"Art_Nouveau\",\"Baroque\",\"Color_Field_Painting\",\"Contemporary_Realism\",\"Cubism\",\"Early_Renaissance\",\"Expressionism\",\"Fauvism\",\"High_Renaissance\",\"Impressionism\",\"Mannerism_Late_Renaissance\",\"Minimalism\",\"Naive_Art_Primitivism\",\"New_Realism\",\"Northern_Renaissance\",\"Pointillism\",\"Pop_Art\",\"Post_Impressionism\",\"Realism\",\"Rococo\",\"Romanticism\",\"Symbolism\",\"Synthetic_Cubism\",\"Ukiyo_e\"]\n",
    "\n",
    "Examples of correct outputs:\n",
    "{\n",
    "  \"watermarks\": 0,\n",
    "  \"text\": \"\",\n",
    "  \"main_object\": \"Woman with a parasol\",\n",
    "  \"style\": \"Impressionism\"\n",
    "}\n",
    "{\n",
    "  \"watermarks\": 1,\n",
    "  \"text\": \"COPYRIGHT\",\n",
    "  \"main_object\": \"Landscape with mountains\",\n",
    "  \"style\": \"Post_Impressionism\"\n",
    "}\n",
    "{\n",
    "  \"watermarks\": 2,\n",
    "  \"text\": \"VOID 4\",\n",
    "  \"main_object\": \"City buildings\",\n",
    "  \"style\": \"Cubism\"\n",
    "}\n",
    "\"\"\"\n",
    "# Compose chat input\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},  # <-- your image placeholder token\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Stream output while enforcing schema\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=128,\n",
    "    use_cache=True,\n",
    "    temperature=0.7,  # lower temp = more reliable structured JSON\n",
    "    min_p=0.1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
